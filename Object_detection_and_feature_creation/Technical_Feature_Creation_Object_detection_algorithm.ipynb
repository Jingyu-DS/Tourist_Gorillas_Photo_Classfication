{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8d1297de",
      "metadata": {
        "id": "8d1297de"
      },
      "source": [
        "# Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method used in this object detection algorithm is EfficientDet-Lite, a pretrained object detector. This is trained on COCO 2017 eval set and achieves mAP 41.5. "
      ],
      "metadata": {
        "id": "-KLlYbu6zWz5"
      },
      "id": "-KLlYbu6zWz5"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU-FtCuNDIIN",
        "outputId": "cd1af024-b51c-4238-9fb4-e56c632f1d9f"
      },
      "id": "EU-FtCuNDIIN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6e2e35f",
      "metadata": {
        "id": "c6e2e35f"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import distance as dist\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "import glob\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42362419",
      "metadata": {
        "id": "42362419"
      },
      "outputs": [],
      "source": [
        "detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/lite4/detection/1\") #link with image classifier\n",
        "#link is subject to change due to updates.\n",
        "#If this cell throws an error, increase the number in front of \"lite\" by 1. \n",
        "#Ex: lite4 -> lite5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv('/content/gdrive/MyDrive/GTVD-(DS440-Team1)/Data/labels.csv', sep=';', index_col='ID') # Download the label file from github\n",
        "labels = labels['SUPER CATEGORY']"
      ],
      "metadata": {
        "id": "lD0g5q8B6q9K"
      },
      "id": "lD0g5q8B6q9K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_animal_person(pred_labels, pred_scores):\n",
        "  prob_greater_0_5 = [index for index,value in enumerate(pred_scores) if value > 0.5]\n",
        "  final_label = []\n",
        "  for i in prob_greater_0_5:\n",
        "    final_label.append(pred_labels[i])\n",
        "  \n",
        "  return set(['person', 'animal']) <= set(final_label)"
      ],
      "metadata": {
        "id": "9s4VA3W962DT"
      },
      "id": "9s4VA3W962DT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "096a66ab",
      "metadata": {
        "id": "096a66ab"
      },
      "outputs": [],
      "source": [
        "def detect_objects(input_filepath, output_filepath, width=1028, height=1028, show=False):\n",
        "  # load data and preprocessing\n",
        "  img = cv2.imread(input_filepath)\n",
        "  if width is None or height == None:\n",
        "    inp = img\n",
        "  else:\n",
        "    inp = cv2.resize(img, (width, height))\n",
        "  rgb = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
        "  rgb_tensor = tf.convert_to_tensor(rgb, dtype = tf.uint8)\n",
        "  rgb_tensor = tf.expand_dims(rgb_tensor, 0)\n",
        "\n",
        "  # run model\n",
        "  boxes, scores, classes, num_detection = detector(rgb_tensor)\n",
        "\n",
        "  # post processing\n",
        "  pred_labels = classes.numpy().astype('int')[0] \n",
        "  pred_labels = [labels[i] for i in pred_labels]\n",
        "  pred_boxes = boxes.numpy()[0].astype('int')\n",
        "  pred_scores = scores.numpy()[0]\n",
        "  \n",
        "  detect_objects.checker = check_animal_person(pred_labels, pred_scores)\n",
        "  \n",
        "  if detect_objects.checker:\n",
        "    # draw boxes on the figure\n",
        "    output_image = rgb\n",
        "    detect_objects.fileID = output_filepath.split('/')[-1]\n",
        "    human_coordinates = []\n",
        "    animal_coordinates = []\n",
        "    for score, (ymin, xmin, ymax, xmax), label in zip(pred_scores, pred_boxes, pred_labels):\n",
        "      if score < 0.25:\n",
        "        continue\n",
        "\n",
        "      if score > 0.25 and label == 'person':\n",
        "        human_coordinates.append((ymin, xmin, ymax, xmax))\n",
        "      \n",
        "      if score > 0.25 and label == 'animal':\n",
        "        animal_coordinates.append((ymin, xmin, ymax, xmax))\n",
        "\n",
        "      # draw box    \n",
        "      # i am thinking just \n",
        "      # score_txt = f'{100 * round(score)}%'\n",
        "      score_txt = f'{round(100 * score)}%'\n",
        "      output_image = cv2.rectangle(output_image, (xmin, ymax),(xmax, ymin),(0,255,0),2)\n",
        "  \n",
        "\n",
        "      # put text\n",
        "      font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "      output_image = cv2.putText(output_image, label, (xmin, ymax-10), font, 1.5, (255,0,0), 2, cv2.LINE_AA)\n",
        "      # output_image = cv2.putText(output_image, score_txt, (xmax, ymax-10), font, 1.5, (255,0,0), 2, cv2.LINE_AA)\n",
        "      \n",
        "    # save figure to the specified path\n",
        "    ### if the predicted labels do not contain human and animals at the same time \n",
        "    ### we will not save the image to the output file\n",
        "    cv2_output_image = cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(output_filepath, cv2_output_image)\n",
        "    # print(human_coordinates)\n",
        "    # print(animal_coordinates)\n",
        "    detect_objects.human_target, detect_objects.animal_target, detect_objects.min_dis, detect_objects.human_width, detect_objects.human_length, detect_objects.animal_width, detect_objects.animal_length, detect_objects.human_area, detect_objects.animal_area, detect_objects.area_ratio = feature_creation(human_coordinates, animal_coordinates)\n",
        "    print(detect_objects.fileID)\n",
        "    print(detect_objects.min_dis)\n",
        "  \n",
        "    # show figure if \"show\" is true\n",
        "    if show:\n",
        "      plt.figure(figsize=(10,10))\n",
        "      plt.imshow(output_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You could create feature you want here. \n",
        "def feature_creation(human_coordinates, animal_coordinates):\n",
        "  min_dis = 10000\n",
        "  human_index = 0\n",
        "  animal_index = 0\n",
        "  for i in range(len(human_coordinates)):\n",
        "    for j in range(len(animal_coordinates)):\n",
        "      human_mid_x = (human_coordinates[i][1] + human_coordinates[i][3])/2\n",
        "      human_mid_y = (human_coordinates[i][0] + human_coordinates[i][2])/2\n",
        "      animal_mid_x = (animal_coordinates[j][1] + animal_coordinates[j][3])/2\n",
        "      animal_mid_y = (animal_coordinates[j][0] + animal_coordinates[j][2])/2\n",
        "      distance = ((human_mid_x - animal_mid_x)**2 + (human_mid_y - animal_mid_y)**2)**0.5\n",
        "      if distance < min_dis:\n",
        "        min_dis = distance\n",
        "        human_index = i\n",
        "        animal_index = j\n",
        "      else:\n",
        "        continue\n",
        "  # print(human_index)\n",
        "  # print(animal_index)\n",
        "  human_target = human_coordinates[human_index]\n",
        "  animal_target = animal_coordinates[animal_index]\n",
        "  human_width = abs(human_target[3]-human_target[1])\n",
        "  human_length = abs(human_target[2]-human_target[0])\n",
        "  animal_width = abs(animal_target[3]-animal_target[1])\n",
        "  animal_length = abs(animal_target[2]-animal_target[0])\n",
        "  human_area = human_width * human_length\n",
        "  animal_area = animal_width * animal_length\n",
        "\n",
        "  area_list = [human_area, animal_area]\n",
        "  area_ratio = max(area_list) / min(area_list)\n",
        "\n",
        "  return human_target, animal_target, min_dis, human_width, human_length, animal_width, animal_length, human_area, animal_area, area_ratio"
      ],
      "metadata": {
        "id": "Pj7Vnbe4KmrU"
      },
      "id": "Pj7Vnbe4KmrU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.chdir('/content/gdrive/My Drive/Pig_new')\n",
        "# !ls"
      ],
      "metadata": {
        "id": "T8nY85BIFYBg"
      },
      "id": "T8nY85BIFYBg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install natsort"
      ],
      "metadata": {
        "id": "BcY3jx92a8WY"
      },
      "id": "BcY3jx92a8WY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from natsort import natsorted"
      ],
      "metadata": {
        "id": "q8i6upNkbCRO"
      },
      "id": "q8i6upNkbCRO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.listdir casues some randomness when reading the filenames\n",
        "# This function helps make sure it will follow the order exactly in the drive \n",
        "# Then, the table can be directly used along with the images when training\n",
        "# import re\n",
        "# numbers = re.compile(r'(\\d+)')\n",
        "# def numericalSort(value):\n",
        "#     parts = numbers.split(value)\n",
        "#     parts[1::2] = map(int, parts[1::2])\n",
        "#     return parts"
      ],
      "metadata": {
        "id": "UYYeiNUHBZHm"
      },
      "id": "UYYeiNUHBZHm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def sorted_alphanumeric(data):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
        "    return sorted(data, key=alphanum_key)"
      ],
      "metadata": {
        "id": "hHRiI4ekb1XC"
      },
      "id": "hHRiI4ekb1XC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c97937c2",
      "metadata": {
        "id": "c97937c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404772f1-b75c-4e28-fa50-d8a7cf0b3a38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "input_folder = \"/content/gdrive/MyDrive/GTVD-(DS440-Team1)/Data/Data_collection1/Benchmark_validation/Non_violation\" # Set to the location of input file\n",
        "filenames = sorted_alphanumeric(os.listdir(input_folder))\n",
        "extensions = ['jpg', 'bmp', 'png', 'JPG', 'JPEG', 'jpeg']\n",
        "filenames = [filename for filename in filenames] #if image type is not .jpg, replace with appropirate photo type\n",
        "# filenames = sorted(filenames, key=numericalSort)\n",
        "# filenames = natsorted(filenames)\n",
        "len(filenames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b81897",
      "metadata": {
        "id": "e5b81897"
      },
      "outputs": [],
      "source": [
        "output_folder = \"/content/gdrive/MyDrive/Multi_input_data/Non-Violation_validation_lion\" # Create a destination folder for images with objects detected\n",
        "os.makedirs(output_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757f514e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "757f514e",
        "outputId": "aaab1786-688c-4605-97d6-0d55dbe06281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1 / 45 - IMG_1736.JPG\n",
            "Processing 2 / 45 - IMG_1737.JPG\n",
            "Processing 3 / 45 - IMG_1738.JPG\n",
            "Processing 4 / 45 - IMG_1739.JPG\n",
            "Processing 5 / 45 - IMG_1741.JPG\n",
            "Processing 6 / 45 - IMG_1742.JPG\n",
            "IMG_1742.JPG\n",
            "785.4457333259886\n",
            "Processing 7 / 45 - IMG_1743.JPG\n",
            "IMG_1743.JPG\n",
            "780.435295203901\n",
            "Processing 8 / 45 - IMG_1744.JPG\n",
            "Processing 9 / 45 - IMG_1815.JPG\n",
            "Processing 10 / 45 - IMG_1816.JPG\n",
            "Processing 11 / 45 - IMG_1817.JPG\n",
            "Processing 12 / 45 - IMG_1828.JPG\n",
            "Processing 13 / 45 - IMG_1833.JPG\n",
            "Processing 14 / 45 - IMG_1843.JPG\n",
            "Processing 15 / 45 - IMG_1844.JPG\n",
            "IMG_1844.JPG\n",
            "591.3281660803923\n",
            "Processing 16 / 45 - IMG_1845.JPG\n",
            "IMG_1845.JPG\n",
            "539.0326984515874\n",
            "Processing 17 / 45 - IMG_1882.JPG\n",
            "Processing 18 / 45 - IMG_1883.JPG\n",
            "Processing 19 / 45 - IMG_1884.JPG\n",
            "Processing 20 / 45 - IMG_2076.JPG\n",
            "Processing 21 / 45 - IMG_2080.JPG\n",
            "Processing 22 / 45 - IMG_2082.JPG\n",
            "Processing 23 / 45 - IMG_2083.JPG\n",
            "Processing 24 / 45 - IMG_2109.JPG\n",
            "Processing 25 / 45 - IMG_2592.JPG\n",
            "Processing 26 / 45 - IMG_2593.JPG\n",
            "Processing 27 / 45 - IMG_2594.JPG\n",
            "Processing 28 / 45 - IMG_2595.JPG\n",
            "Processing 29 / 45 - IMG_2596.JPG\n",
            "Processing 30 / 45 - IMG_2597.JPG\n",
            "Processing 31 / 45 - IMG_2598.JPG\n",
            "Processing 32 / 45 - IMG_2599.JPG\n",
            "Processing 33 / 45 - IMG_4986.JPG\n",
            "Processing 34 / 45 - IMG_4987.JPG\n",
            "Processing 35 / 45 - IMG_4988.JPG\n",
            "Processing 36 / 45 - IMG_4989.JPG\n",
            "Processing 37 / 45 - IMG_4990.JPG\n",
            "Processing 38 / 45 - IMG_5028.JPG\n",
            "Processing 39 / 45 - IMG_5029.JPG\n",
            "Processing 40 / 45 - IMG_5033.JPG\n",
            "Processing 41 / 45 - IMG_8559.JPG\n",
            "Processing 42 / 45 - IMG_8561.JPG\n",
            "Processing 43 / 45 - IMG_8562.JPG\n",
            "Processing 44 / 45 - IMG_8563.JPG\n",
            "IMG_8563.JPG\n",
            "449.65125375117105\n",
            "Processing 45 / 45 - IMG_8564.JPG\n"
          ]
        }
      ],
      "source": [
        "fileID = []\n",
        "min_dis = []\n",
        "human_width = []\n",
        "human_length = []\n",
        "human_area = []\n",
        "animal_width = []\n",
        "animal_length = []\n",
        "animal_area = []\n",
        "area_ratio = []\n",
        "human_target = []\n",
        "animal_target = []\n",
        "\n",
        "for index, filename in enumerate(filenames, 1):\n",
        "  print(\"Processing {} / {} - {}\".format(index, len(filenames), filename))\n",
        "  detect_objects(\n",
        "    input_filepath = os.path.join(input_folder, filename),\n",
        "    output_filepath = os.path.join(output_folder, filename),\n",
        "    show=False, # you can turn this on if needed  \n",
        "  )\n",
        "  if detect_objects.checker:\n",
        "    fileID.append(detect_objects.fileID)\n",
        "    min_dis.append(detect_objects.min_dis)\n",
        "    human_width.append(detect_objects.human_width)\n",
        "    human_length.append(detect_objects.human_length)\n",
        "    animal_width.append(detect_objects.animal_width)\n",
        "    animal_length.append(detect_objects.animal_length)\n",
        "    human_area.append(detect_objects.human_area)\n",
        "    animal_area.append(detect_objects.animal_area)\n",
        "    area_ratio.append(detect_objects.area_ratio)\n",
        "    human_target.append(detect_objects.human_target)\n",
        "    animal_target.append(detect_objects.animal_target)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(fileID, min_dis, human_target, human_width, human_length, human_area, animal_target, animal_width, animal_length, animal_area, area_ratio)),\n",
        "               columns =['File Name', 'Closest Distance', 'Human Target', 'Human Width', 'Human Length', \n",
        "                         'Human Area', 'Animal Taget', 'Animal Width', 'Animal Length', 'Animal Area', 'Area Ratio'])\n",
        "print(df.head())\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkcycZ_v5844",
        "outputId": "29c3e9e0-6051-463a-954c-ba584947cb0f"
      },
      "id": "DkcycZ_v5844",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      File Name  Closest Distance           Human Target  Human Width  \\\n",
            "0  IMG_1742.JPG        785.445733   (241, 91, 1016, 340)          249   \n",
            "1  IMG_1743.JPG        780.435295   (237, 57, 1023, 321)          264   \n",
            "2  IMG_1844.JPG        591.328166  (10, 326, 1023, 1019)          693   \n",
            "3  IMG_1845.JPG        539.032698  (88, 358, 1009, 1026)          668   \n",
            "4  IMG_8563.JPG        449.651254   (393, 635, 490, 694)           59   \n",
            "\n",
            "   Human Length  Human Area           Animal Taget  Animal Width  \\\n",
            "0           775      192975  (235, 829, 346, 1020)           191   \n",
            "1           786      207504   (241, 802, 358, 990)           188   \n",
            "2          1013      702009    (600, 11, 709, 184)           173   \n",
            "3           921      615228    (600, 58, 714, 270)           212   \n",
            "4            97        5723   (650, 255, 996, 598)           343   \n",
            "\n",
            "   Animal Length  Animal Area  Area Ratio  \n",
            "0            111        21201    9.102165  \n",
            "1            117        21996    9.433715  \n",
            "2            109        18857   37.228032  \n",
            "3            114        24168   25.456306  \n",
            "4            346       118678   20.737026  \n",
            "(5, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = [0] * df.shape[0]\n",
        "df['Label'] = label\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "eocH-FrW6Wto",
        "outputId": "bb42e90a-739b-4703-b6a6-3c1337beced5"
      },
      "id": "eocH-FrW6Wto",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      File Name  Closest Distance           Human Target  Human Width  \\\n",
              "0  IMG_1742.JPG        785.445733   (241, 91, 1016, 340)          249   \n",
              "1  IMG_1743.JPG        780.435295   (237, 57, 1023, 321)          264   \n",
              "2  IMG_1844.JPG        591.328166  (10, 326, 1023, 1019)          693   \n",
              "3  IMG_1845.JPG        539.032698  (88, 358, 1009, 1026)          668   \n",
              "4  IMG_8563.JPG        449.651254   (393, 635, 490, 694)           59   \n",
              "\n",
              "   Human Length  Human Area           Animal Taget  Animal Width  \\\n",
              "0           775      192975  (235, 829, 346, 1020)           191   \n",
              "1           786      207504   (241, 802, 358, 990)           188   \n",
              "2          1013      702009    (600, 11, 709, 184)           173   \n",
              "3           921      615228    (600, 58, 714, 270)           212   \n",
              "4            97        5723   (650, 255, 996, 598)           343   \n",
              "\n",
              "   Animal Length  Animal Area  Area Ratio  Label  \n",
              "0            111        21201    9.102165      0  \n",
              "1            117        21996    9.433715      0  \n",
              "2            109        18857   37.228032      0  \n",
              "3            114        24168   25.456306      0  \n",
              "4            346       118678   20.737026      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ccd7200-51b9-4fce-82d4-02b997f11995\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>Closest Distance</th>\n",
              "      <th>Human Target</th>\n",
              "      <th>Human Width</th>\n",
              "      <th>Human Length</th>\n",
              "      <th>Human Area</th>\n",
              "      <th>Animal Taget</th>\n",
              "      <th>Animal Width</th>\n",
              "      <th>Animal Length</th>\n",
              "      <th>Animal Area</th>\n",
              "      <th>Area Ratio</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IMG_1742.JPG</td>\n",
              "      <td>785.445733</td>\n",
              "      <td>(241, 91, 1016, 340)</td>\n",
              "      <td>249</td>\n",
              "      <td>775</td>\n",
              "      <td>192975</td>\n",
              "      <td>(235, 829, 346, 1020)</td>\n",
              "      <td>191</td>\n",
              "      <td>111</td>\n",
              "      <td>21201</td>\n",
              "      <td>9.102165</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IMG_1743.JPG</td>\n",
              "      <td>780.435295</td>\n",
              "      <td>(237, 57, 1023, 321)</td>\n",
              "      <td>264</td>\n",
              "      <td>786</td>\n",
              "      <td>207504</td>\n",
              "      <td>(241, 802, 358, 990)</td>\n",
              "      <td>188</td>\n",
              "      <td>117</td>\n",
              "      <td>21996</td>\n",
              "      <td>9.433715</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IMG_1844.JPG</td>\n",
              "      <td>591.328166</td>\n",
              "      <td>(10, 326, 1023, 1019)</td>\n",
              "      <td>693</td>\n",
              "      <td>1013</td>\n",
              "      <td>702009</td>\n",
              "      <td>(600, 11, 709, 184)</td>\n",
              "      <td>173</td>\n",
              "      <td>109</td>\n",
              "      <td>18857</td>\n",
              "      <td>37.228032</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMG_1845.JPG</td>\n",
              "      <td>539.032698</td>\n",
              "      <td>(88, 358, 1009, 1026)</td>\n",
              "      <td>668</td>\n",
              "      <td>921</td>\n",
              "      <td>615228</td>\n",
              "      <td>(600, 58, 714, 270)</td>\n",
              "      <td>212</td>\n",
              "      <td>114</td>\n",
              "      <td>24168</td>\n",
              "      <td>25.456306</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IMG_8563.JPG</td>\n",
              "      <td>449.651254</td>\n",
              "      <td>(393, 635, 490, 694)</td>\n",
              "      <td>59</td>\n",
              "      <td>97</td>\n",
              "      <td>5723</td>\n",
              "      <td>(650, 255, 996, 598)</td>\n",
              "      <td>343</td>\n",
              "      <td>346</td>\n",
              "      <td>118678</td>\n",
              "      <td>20.737026</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ccd7200-51b9-4fce-82d4-02b997f11995')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ccd7200-51b9-4fce-82d4-02b997f11995 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ccd7200-51b9-4fce-82d4-02b997f11995');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('non-violation_validation.csv')\n",
        "!cp non-violation_validation.csv \"/content/gdrive/MyDrive/Multi_input_data\""
      ],
      "metadata": {
        "id": "QCEjcnii6ihS"
      },
      "id": "QCEjcnii6ihS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Technical_Feature_Creation_Object_detection_algorithm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}