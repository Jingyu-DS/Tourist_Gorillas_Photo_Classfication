{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8d1297de",
      "metadata": {
        "id": "8d1297de"
      },
      "source": [
        "# Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method used in this object detection algorithm is EfficientDet-Lite, a pretrained object detector. This is trained on COCO 2017 eval set and achieves mAP 41.5. "
      ],
      "metadata": {
        "id": "-KLlYbu6zWz5"
      },
      "id": "-KLlYbu6zWz5"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU-FtCuNDIIN",
        "outputId": "00710019-7425-4ddc-ea64-ac1de867687c"
      },
      "id": "EU-FtCuNDIIN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6e2e35f",
      "metadata": {
        "id": "c6e2e35f"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import distance as dist\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "import glob\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42362419",
      "metadata": {
        "id": "42362419"
      },
      "outputs": [],
      "source": [
        "detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/lite4/detection/1\") #link with image classifier\n",
        "#link is subject to change due to updates.\n",
        "#If this cell throws an error, increase the number in front of \"lite\" by 1. \n",
        "#Ex: lite4 -> lite5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv('/content/gdrive/MyDrive/labels.csv', sep=';', index_col='ID') # Download the label file from github\n",
        "labels = labels['SUPER CATEGORY']"
      ],
      "metadata": {
        "id": "lD0g5q8B6q9K"
      },
      "id": "lD0g5q8B6q9K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "096a66ab",
      "metadata": {
        "id": "096a66ab"
      },
      "outputs": [],
      "source": [
        "def detect_objects(input_filepath, output_filepath, width=1028, height=1028, show=False):\n",
        "  # load data and preprocessing\n",
        "  img = cv2.imread(input_filepath)\n",
        "  if width is None or height == None:\n",
        "    inp = img\n",
        "  else:\n",
        "    inp = cv2.resize(img, (width, height))\n",
        "  rgb = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
        "  rgb_tensor = tf.convert_to_tensor(rgb, dtype = tf.uint8)\n",
        "  rgb_tensor = tf.expand_dims(rgb_tensor, 0)\n",
        "\n",
        "  # run model\n",
        "  boxes, scores, classes, num_detection = detector(rgb_tensor)\n",
        "\n",
        "  # post processing\n",
        "  pred_labels = classes.numpy().astype('int')[0] \n",
        "  pred_labels = [labels[i] for i in pred_labels]\n",
        "  pred_boxes = boxes.numpy()[0].astype('int')\n",
        "  pred_scores = scores.numpy()[0]\n",
        "  \n",
        "  # detect_objects.checker = check_animal_person(pred_labels, pred_scores)\n",
        "  \n",
        "  # draw boxes on the figure\n",
        "  output_image = rgb\n",
        "  detect_objects.fileID = output_filepath.split('/')[-1]\n",
        "  human_coordinates = []\n",
        "  \n",
        "  # animal_coordinates = []\n",
        "  for score, (ymin, xmin, ymax, xmax), label in zip(pred_scores, pred_boxes, pred_labels):\n",
        "    if score < 0.25:\n",
        "      continue\n",
        "\n",
        "    if score > 0.25 and label == 'person':\n",
        "      human_coordinates.append((ymin, xmin, ymax, xmax))\n",
        "      \n",
        "    # if score > 0.25 and label == 'animal':\n",
        "      # animal_coordinates.append((ymin, xmin, ymax, xmax))\n",
        "\n",
        "    # draw box    \n",
        "    # i am thinking just \n",
        "    # score_txt = f'{100 * round(score)}%'\n",
        "    score_txt = f'{round(100 * score)}%'\n",
        "    output_image = cv2.rectangle(output_image, (xmin, ymax),(xmax, ymin),(0,255,0),2)\n",
        "  \n",
        "\n",
        "    # put text\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    output_image = cv2.putText(output_image, label, (xmin, ymax-10), font, 1.5, (255,0,0), 2, cv2.LINE_AA)\n",
        "    # output_image = cv2.putText(output_image, score_txt, (xmax, ymax-10), font, 1.5, (255,0,0), 2, cv2.LINE_AA)\n",
        "      \n",
        "  # save figure to the specified path\n",
        "  ### if the predicted labels do not contain human and animals at the same time \n",
        "  ### we will not save the image to the output file\n",
        "  cv2_output_image = cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)\n",
        "  cv2.imwrite(output_filepath, cv2_output_image)\n",
        "  # print(human_coordinates)\n",
        "  # print(animal_coordinates)\n",
        "  if len(human_coordinates) >=2:\n",
        "    detect_objects.human_target, detect_objects.animal_target, detect_objects.min_dis, detect_objects.human_width, detect_objects.human_length, detect_objects.animal_width, detect_objects.animal_length, detect_objects.human_area, detect_objects.animal_area, detect_objects.area_ratio = feature_creation(human_coordinates)\n",
        "    print(detect_objects.fileID)\n",
        "    print(detect_objects.min_dis)\n",
        "    print(human_coordinates)\n",
        "  \n",
        "  # show figure if \"show\" is true\n",
        "  if show:\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(output_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You could create feature you want here. \n",
        "def feature_creation(human_coordinates):\n",
        "  min_dis = 100000\n",
        "  human_index = 0\n",
        "  human2_index = 0\n",
        "  for i in range(len(human_coordinates)-1):\n",
        "    for j in range(i+1, len(human_coordinates)):\n",
        "      human_mid_x = (human_coordinates[i][1] + human_coordinates[i][3])/2\n",
        "      human_mid_y = (human_coordinates[i][0] + human_coordinates[i][2])/2\n",
        "      human2_mid_x = (human_coordinates[j][1] + human_coordinates[j][3])/2\n",
        "      human2_mid_y = (human_coordinates[j][0] + human_coordinates[j][2])/2\n",
        "      distance = ((human_mid_x - human2_mid_x)**2 + (human_mid_y - human2_mid_y)**2)**0.5\n",
        "      if distance < min_dis:\n",
        "        min_dis = distance\n",
        "        human_index = i\n",
        "        human2_index = j\n",
        "      else:\n",
        "        continue\n",
        "  print(human_index)\n",
        "  print(human2_index)\n",
        "  human_target = human_coordinates[human_index]\n",
        "  animal_target = human_coordinates[human2_index]\n",
        "  human_width = abs(human_target[3]-human_target[1])\n",
        "  human_length = abs(human_target[2]-human_target[0])\n",
        "  animal_width = abs(animal_target[3]-animal_target[1])\n",
        "  animal_length = abs(animal_target[2]-animal_target[0])\n",
        "  human_area = human_width * human_length\n",
        "  animal_area = animal_width * animal_length\n",
        "\n",
        "  area_list = [human_area, animal_area]\n",
        "  area_ratio = max(area_list) / min(area_list)\n",
        "\n",
        "  return human_target, animal_target, min_dis, human_width, human_length, animal_width, animal_length, human_area, animal_area, area_ratio"
      ],
      "metadata": {
        "id": "Pj7Vnbe4KmrU"
      },
      "id": "Pj7Vnbe4KmrU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.chdir('/content/gdrive/My Drive/Pig_new')\n",
        "# !ls"
      ],
      "metadata": {
        "id": "T8nY85BIFYBg"
      },
      "id": "T8nY85BIFYBg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install natsort"
      ],
      "metadata": {
        "id": "BcY3jx92a8WY"
      },
      "id": "BcY3jx92a8WY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from natsort import natsorted"
      ],
      "metadata": {
        "id": "q8i6upNkbCRO"
      },
      "id": "q8i6upNkbCRO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.listdir casues some randomness when reading the filenames\n",
        "# This function helps make sure it will follow the order exactly in the drive \n",
        "# Then, the table can be directly used along with the images when training\n",
        "# import re\n",
        "# numbers = re.compile(r'(\\d+)')\n",
        "# def numericalSort(value):\n",
        "#     parts = numbers.split(value)\n",
        "#     parts[1::2] = map(int, parts[1::2])\n",
        "#     return parts"
      ],
      "metadata": {
        "id": "UYYeiNUHBZHm"
      },
      "id": "UYYeiNUHBZHm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def sorted_alphanumeric(data):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
        "    return sorted(data, key=alphanum_key)"
      ],
      "metadata": {
        "id": "hHRiI4ekb1XC"
      },
      "id": "hHRiI4ekb1XC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c97937c2",
      "metadata": {
        "id": "c97937c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31076cbe-6468-4064-fb30-c14368148430"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "input_folder = \"/content/gdrive/MyDrive/human-human-raw/Non_violation\" # Set to the location of input file\n",
        "filenames = sorted_alphanumeric(os.listdir(input_folder))\n",
        "extensions = ['jpg', 'bmp', 'png', 'JPG', 'JPEG', 'jpeg']\n",
        "filenames = [filename for filename in filenames] #if image type is not .jpg, replace with appropirate photo type\n",
        "# filenames = sorted(filenames, key=numericalSort)\n",
        "# filenames = natsorted(filenames)\n",
        "len(filenames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b81897",
      "metadata": {
        "id": "e5b81897"
      },
      "outputs": [],
      "source": [
        "output_folder = \"/content/gdrive/MyDrive/human-human-raw/Non_violation_detected\" # Create a destination folder for images with objects detected\n",
        "os.makedirs(output_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757f514e",
      "metadata": {
        "id": "757f514e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ae0449-39b1-4e0d-dd74-6ca7f70d7889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1 / 14 - download (1).jpg\n",
            "0\n",
            "2\n",
            "download (1).jpg\n",
            "191.4451618610405\n",
            "[(66, 15, 367, 187), (89, 851, 378, 1016), (58, 21, 756, 219)]\n",
            "Processing 2 / 14 - download (2).jpg\n",
            "0\n",
            "1\n",
            "download (2).jpg\n",
            "436.0071673722807\n",
            "[(499, 270, 866, 389), (512, 710, 858, 821)]\n",
            "Processing 3 / 14 - images (1).jpg\n",
            "0\n",
            "1\n",
            "images (1).jpg\n",
            "471.0883675065645\n",
            "[(0, 657, 362, 792), (0, 184, 806, 434)]\n",
            "Processing 4 / 14 - images (2).jpg\n",
            "1\n",
            "2\n",
            "images (2).jpg\n",
            "39.05444917035702\n",
            "[(295, 163, 646, 242), (287, 48, 545, 107), (304, 15, 503, 66), (296, 89, 581, 150), (225, 790, 701, 911), (255, 253, 713, 349)]\n",
            "Processing 5 / 14 - images (4).jpg\n",
            "0\n",
            "1\n",
            "images (4).jpg\n",
            "540.5018501355939\n",
            "[(15, 512, 1020, 979), (323, 113, 1024, 343)]\n",
            "Processing 6 / 14 - images (5).jpg\n",
            "0\n",
            "1\n",
            "images (5).jpg\n",
            "599.1804819918619\n",
            "[(69, 191, 659, 347), (55, 733, 1010, 955)]\n",
            "Processing 7 / 14 - images (6).jpg\n",
            "Processing 8 / 14 - images (11).jpg\n",
            "1\n",
            "2\n",
            "images (11).jpg\n",
            "457.5784085815239\n",
            "[(472, 0, 648, 183), (340, 527, 444, 577), (492, 904, 686, 1026)]\n",
            "Processing 9 / 14 - images (12).jpg\n",
            "0\n",
            "1\n",
            "images (12).jpg\n",
            "632.4011780507686\n",
            "[(66, 404, 350, 680), (651, 172, 1026, 814)]\n",
            "Processing 10 / 14 - images (19).jpg\n",
            "0\n",
            "1\n",
            "images (19).jpg\n",
            "575.4602505820884\n",
            "[(199, 312, 960, 455), (38, 865, 828, 1015)]\n",
            "Processing 11 / 14 - images (22).jpg\n",
            "0\n",
            "1\n",
            "images (22).jpg\n",
            "693.1069542285663\n",
            "[(408, 79, 1020, 279), (172, 732, 1026, 993)]\n",
            "Processing 12 / 14 - images (25).jpg\n",
            "0\n",
            "2\n",
            "images (25).jpg\n",
            "363.40198128243605\n",
            "[(500, 389, 783, 547), (515, 889, 715, 989), (444, 112, 539, 162)]\n",
            "Processing 13 / 14 - images (26).jpg\n",
            "Processing 14 / 14 - images (29).jpg\n",
            "0\n",
            "1\n",
            "images (29).jpg\n",
            "591.0171317313907\n",
            "[(145, 118, 500, 225), (151, 687, 716, 817)]\n"
          ]
        }
      ],
      "source": [
        "fileID = []\n",
        "min_dis = []\n",
        "human_width = []\n",
        "human_length = []\n",
        "human_area = []\n",
        "animal_width = []\n",
        "animal_length = []\n",
        "animal_area = []\n",
        "area_ratio = []\n",
        "human_target = []\n",
        "animal_target = []\n",
        "\n",
        "for index, filename in enumerate(filenames, 1):\n",
        "  print(\"Processing {} / {} - {}\".format(index, len(filenames), filename))\n",
        "  detect_objects(\n",
        "    input_filepath = os.path.join(input_folder, filename),\n",
        "    output_filepath = os.path.join(output_folder, filename),\n",
        "    show=False, # you can turn this on if needed  \n",
        "  )\n",
        "\n",
        "  fileID.append(detect_objects.fileID)\n",
        "  min_dis.append(detect_objects.min_dis)\n",
        "  human_width.append(detect_objects.human_width)\n",
        "  human_length.append(detect_objects.human_length)\n",
        "  animal_width.append(detect_objects.animal_width)\n",
        "  animal_length.append(detect_objects.animal_length)\n",
        "  human_area.append(detect_objects.human_area)\n",
        "  animal_area.append(detect_objects.animal_area)\n",
        "  area_ratio.append(detect_objects.area_ratio)\n",
        "  human_target.append(detect_objects.human_target)\n",
        "  animal_target.append(detect_objects.animal_target)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(fileID, min_dis, human_target, human_width, human_length, human_area, animal_target, animal_width, animal_length, animal_area, area_ratio)),\n",
        "               columns =['File Name', 'Closest Distance', 'Human Target', 'Human Width', 'Human Length', \n",
        "                         'Human Area', 'Animal Taget', 'Animal Width', 'Animal Length', 'Animal Area', 'Area Ratio'])\n",
        "print(df.head())\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkcycZ_v5844",
        "outputId": "ee0e8758-45eb-449c-c8eb-eb7f3f535e10"
      },
      "id": "DkcycZ_v5844",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          File Name  Closest Distance          Human Target  Human Width  \\\n",
            "0  download (1).jpg        191.445162    (66, 15, 367, 187)          172   \n",
            "1  download (2).jpg        436.007167  (499, 270, 866, 389)          119   \n",
            "2    images (1).jpg        471.088368    (0, 657, 362, 792)          135   \n",
            "3    images (2).jpg         39.054449   (287, 48, 545, 107)           59   \n",
            "4    images (4).jpg        540.501850  (15, 512, 1020, 979)          467   \n",
            "\n",
            "   Human Length  Human Area           Animal Taget  Animal Width  \\\n",
            "0           301       51772     (58, 21, 756, 219)           198   \n",
            "1           367       43673   (512, 710, 858, 821)           111   \n",
            "2           362       48870     (0, 184, 806, 434)           250   \n",
            "3           258       15222     (304, 15, 503, 66)            51   \n",
            "4          1005      469335  (323, 113, 1024, 343)           230   \n",
            "\n",
            "   Animal Length  Animal Area  Area Ratio  \n",
            "0            698       138204    2.669474  \n",
            "1            346        38406    1.137140  \n",
            "2            806       201500    4.123184  \n",
            "3            199        10149    1.499852  \n",
            "4            701       161230    2.910966  \n",
            "(14, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = [0] * df.shape[0]\n",
        "df['Label'] = label\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "eocH-FrW6Wto",
        "outputId": "d3d1ff87-c71b-4e4e-a96c-162951acdd00"
      },
      "id": "eocH-FrW6Wto",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           File Name  Closest Distance          Human Target  Human Width  \\\n",
              "0   download (1).jpg        191.445162    (66, 15, 367, 187)          172   \n",
              "1   download (2).jpg        436.007167  (499, 270, 866, 389)          119   \n",
              "2     images (1).jpg        471.088368    (0, 657, 362, 792)          135   \n",
              "3     images (2).jpg         39.054449   (287, 48, 545, 107)           59   \n",
              "4     images (4).jpg        540.501850  (15, 512, 1020, 979)          467   \n",
              "5     images (5).jpg        599.180482   (69, 191, 659, 347)          156   \n",
              "6     images (6).jpg        599.180482   (69, 191, 659, 347)          156   \n",
              "7    images (11).jpg        457.578409  (340, 527, 444, 577)           50   \n",
              "8    images (12).jpg        632.401178   (66, 404, 350, 680)          276   \n",
              "9    images (19).jpg        575.460251  (199, 312, 960, 455)          143   \n",
              "10   images (22).jpg        693.106954  (408, 79, 1020, 279)          200   \n",
              "11   images (25).jpg        363.401981  (500, 389, 783, 547)          158   \n",
              "12   images (26).jpg        363.401981  (500, 389, 783, 547)          158   \n",
              "13   images (29).jpg        591.017132  (145, 118, 500, 225)          107   \n",
              "\n",
              "    Human Length  Human Area           Animal Taget  Animal Width  \\\n",
              "0            301       51772     (58, 21, 756, 219)           198   \n",
              "1            367       43673   (512, 710, 858, 821)           111   \n",
              "2            362       48870     (0, 184, 806, 434)           250   \n",
              "3            258       15222     (304, 15, 503, 66)            51   \n",
              "4           1005      469335  (323, 113, 1024, 343)           230   \n",
              "5            590       92040   (55, 733, 1010, 955)           222   \n",
              "6            590       92040   (55, 733, 1010, 955)           222   \n",
              "7            104        5200  (492, 904, 686, 1026)           122   \n",
              "8            284       78384  (651, 172, 1026, 814)           642   \n",
              "9            761      108823   (38, 865, 828, 1015)           150   \n",
              "10           612      122400  (172, 732, 1026, 993)           261   \n",
              "11           283       44714   (444, 112, 539, 162)            50   \n",
              "12           283       44714   (444, 112, 539, 162)            50   \n",
              "13           355       37985   (151, 687, 716, 817)           130   \n",
              "\n",
              "    Animal Length  Animal Area  Area Ratio  Label  \n",
              "0             698       138204    2.669474      0  \n",
              "1             346        38406    1.137140      0  \n",
              "2             806       201500    4.123184      0  \n",
              "3             199        10149    1.499852      0  \n",
              "4             701       161230    2.910966      0  \n",
              "5             955       212010    2.303455      0  \n",
              "6             955       212010    2.303455      0  \n",
              "7             194        23668    4.551538      0  \n",
              "8             375       240750    3.071418      0  \n",
              "9             790       118500    1.088924      0  \n",
              "10            854       222894    1.821029      0  \n",
              "11             95         4750    9.413474      0  \n",
              "12             95         4750    9.413474      0  \n",
              "13            565        73450    1.933658      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3088de6-741a-4550-8923-e9bcf3cb14fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>Closest Distance</th>\n",
              "      <th>Human Target</th>\n",
              "      <th>Human Width</th>\n",
              "      <th>Human Length</th>\n",
              "      <th>Human Area</th>\n",
              "      <th>Animal Taget</th>\n",
              "      <th>Animal Width</th>\n",
              "      <th>Animal Length</th>\n",
              "      <th>Animal Area</th>\n",
              "      <th>Area Ratio</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>download (1).jpg</td>\n",
              "      <td>191.445162</td>\n",
              "      <td>(66, 15, 367, 187)</td>\n",
              "      <td>172</td>\n",
              "      <td>301</td>\n",
              "      <td>51772</td>\n",
              "      <td>(58, 21, 756, 219)</td>\n",
              "      <td>198</td>\n",
              "      <td>698</td>\n",
              "      <td>138204</td>\n",
              "      <td>2.669474</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>download (2).jpg</td>\n",
              "      <td>436.007167</td>\n",
              "      <td>(499, 270, 866, 389)</td>\n",
              "      <td>119</td>\n",
              "      <td>367</td>\n",
              "      <td>43673</td>\n",
              "      <td>(512, 710, 858, 821)</td>\n",
              "      <td>111</td>\n",
              "      <td>346</td>\n",
              "      <td>38406</td>\n",
              "      <td>1.137140</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>images (1).jpg</td>\n",
              "      <td>471.088368</td>\n",
              "      <td>(0, 657, 362, 792)</td>\n",
              "      <td>135</td>\n",
              "      <td>362</td>\n",
              "      <td>48870</td>\n",
              "      <td>(0, 184, 806, 434)</td>\n",
              "      <td>250</td>\n",
              "      <td>806</td>\n",
              "      <td>201500</td>\n",
              "      <td>4.123184</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>images (2).jpg</td>\n",
              "      <td>39.054449</td>\n",
              "      <td>(287, 48, 545, 107)</td>\n",
              "      <td>59</td>\n",
              "      <td>258</td>\n",
              "      <td>15222</td>\n",
              "      <td>(304, 15, 503, 66)</td>\n",
              "      <td>51</td>\n",
              "      <td>199</td>\n",
              "      <td>10149</td>\n",
              "      <td>1.499852</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>images (4).jpg</td>\n",
              "      <td>540.501850</td>\n",
              "      <td>(15, 512, 1020, 979)</td>\n",
              "      <td>467</td>\n",
              "      <td>1005</td>\n",
              "      <td>469335</td>\n",
              "      <td>(323, 113, 1024, 343)</td>\n",
              "      <td>230</td>\n",
              "      <td>701</td>\n",
              "      <td>161230</td>\n",
              "      <td>2.910966</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>images (5).jpg</td>\n",
              "      <td>599.180482</td>\n",
              "      <td>(69, 191, 659, 347)</td>\n",
              "      <td>156</td>\n",
              "      <td>590</td>\n",
              "      <td>92040</td>\n",
              "      <td>(55, 733, 1010, 955)</td>\n",
              "      <td>222</td>\n",
              "      <td>955</td>\n",
              "      <td>212010</td>\n",
              "      <td>2.303455</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>images (6).jpg</td>\n",
              "      <td>599.180482</td>\n",
              "      <td>(69, 191, 659, 347)</td>\n",
              "      <td>156</td>\n",
              "      <td>590</td>\n",
              "      <td>92040</td>\n",
              "      <td>(55, 733, 1010, 955)</td>\n",
              "      <td>222</td>\n",
              "      <td>955</td>\n",
              "      <td>212010</td>\n",
              "      <td>2.303455</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>images (11).jpg</td>\n",
              "      <td>457.578409</td>\n",
              "      <td>(340, 527, 444, 577)</td>\n",
              "      <td>50</td>\n",
              "      <td>104</td>\n",
              "      <td>5200</td>\n",
              "      <td>(492, 904, 686, 1026)</td>\n",
              "      <td>122</td>\n",
              "      <td>194</td>\n",
              "      <td>23668</td>\n",
              "      <td>4.551538</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>images (12).jpg</td>\n",
              "      <td>632.401178</td>\n",
              "      <td>(66, 404, 350, 680)</td>\n",
              "      <td>276</td>\n",
              "      <td>284</td>\n",
              "      <td>78384</td>\n",
              "      <td>(651, 172, 1026, 814)</td>\n",
              "      <td>642</td>\n",
              "      <td>375</td>\n",
              "      <td>240750</td>\n",
              "      <td>3.071418</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>images (19).jpg</td>\n",
              "      <td>575.460251</td>\n",
              "      <td>(199, 312, 960, 455)</td>\n",
              "      <td>143</td>\n",
              "      <td>761</td>\n",
              "      <td>108823</td>\n",
              "      <td>(38, 865, 828, 1015)</td>\n",
              "      <td>150</td>\n",
              "      <td>790</td>\n",
              "      <td>118500</td>\n",
              "      <td>1.088924</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>images (22).jpg</td>\n",
              "      <td>693.106954</td>\n",
              "      <td>(408, 79, 1020, 279)</td>\n",
              "      <td>200</td>\n",
              "      <td>612</td>\n",
              "      <td>122400</td>\n",
              "      <td>(172, 732, 1026, 993)</td>\n",
              "      <td>261</td>\n",
              "      <td>854</td>\n",
              "      <td>222894</td>\n",
              "      <td>1.821029</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>images (25).jpg</td>\n",
              "      <td>363.401981</td>\n",
              "      <td>(500, 389, 783, 547)</td>\n",
              "      <td>158</td>\n",
              "      <td>283</td>\n",
              "      <td>44714</td>\n",
              "      <td>(444, 112, 539, 162)</td>\n",
              "      <td>50</td>\n",
              "      <td>95</td>\n",
              "      <td>4750</td>\n",
              "      <td>9.413474</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>images (26).jpg</td>\n",
              "      <td>363.401981</td>\n",
              "      <td>(500, 389, 783, 547)</td>\n",
              "      <td>158</td>\n",
              "      <td>283</td>\n",
              "      <td>44714</td>\n",
              "      <td>(444, 112, 539, 162)</td>\n",
              "      <td>50</td>\n",
              "      <td>95</td>\n",
              "      <td>4750</td>\n",
              "      <td>9.413474</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>images (29).jpg</td>\n",
              "      <td>591.017132</td>\n",
              "      <td>(145, 118, 500, 225)</td>\n",
              "      <td>107</td>\n",
              "      <td>355</td>\n",
              "      <td>37985</td>\n",
              "      <td>(151, 687, 716, 817)</td>\n",
              "      <td>130</td>\n",
              "      <td>565</td>\n",
              "      <td>73450</td>\n",
              "      <td>1.933658</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3088de6-741a-4550-8923-e9bcf3cb14fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3088de6-741a-4550-8923-e9bcf3cb14fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3088de6-741a-4550-8923-e9bcf3cb14fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('Non-Violation.csv')\n",
        "!cp Non-Violation.csv \"/content/gdrive/MyDrive/human-human-raw/\""
      ],
      "metadata": {
        "id": "QCEjcnii6ihS"
      },
      "id": "QCEjcnii6ihS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Stress_testing_people_distancing_detector_Feature_Creation_Object_detection_algorithm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}