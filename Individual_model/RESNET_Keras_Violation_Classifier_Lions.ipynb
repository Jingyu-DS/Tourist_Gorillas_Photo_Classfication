{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGpMrGgYnwsP",
        "outputId": "41b2c2ee-5b25-4367-dc77-e0cb99a134cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6LspcE_pFxT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Directory with our training non-violation pictures\n",
        "train_nonviolation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training/Non_Violation') \n",
        "\n",
        "# Directory with our training violation pictures\n",
        "train_violation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training/Violation') \n",
        "\n",
        "# Directory with our validation non-violation pictures\n",
        "valid_nonviolation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation/Non_violation') \n",
        "\n",
        "# Directory with our validation violation pictures\n",
        "valid_violation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation/Violation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgReGUpCtzjS",
        "outputId": "c706f38c-5bb4-4f0a-8394-b91838e93df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IMG_0490.jpeg', 'IMG_0493.jpeg', 'IMG_0497.jpeg', 'IMG_2793.jpeg', 'IMG_0498.jpeg', 'IMG_2750.jpeg', 'IMG_0494.jpeg', 'IMG_2740.jpeg', 'IMG_2795.jpeg', 'IMG_2777.jpeg']\n",
            "['IMG_5609.JPG', 'IMG_5637.JPG', 'IMG_5623.JPG', 'IMG_5595.JPG', 'IMG_5634.JPG', 'IMG_5581.JPG', 'IMG_5542.JPG', 'IMG_5580.JPG', 'IMG_5635.JPG', 'IMG_5621.JPG']\n",
            "['IMG_8562.JPG', 'IMG_8563.JPG', 'IMG_8564.JPG', 'IMG_8561.JPG', 'IMG_8559.JPG', 'IMG_1736.JPG', 'IMG_1737.JPG', 'IMG_1738.JPG', 'IMG_1739.JPG', 'IMG_1741.JPG']\n",
            "['IMG_8589.JPG', 'IMG_8588.JPG', 'IMG_5656.JPG', 'IMG_5657.JPG', 'IMG_8570.JPG', 'IMG_8565.JPG', 'IMG_5687.JPG', 'IMG_8573.JPG', 'IMG_8567.JPG', 'IMG_8572.JPG']\n",
            "\n",
            "total training nonviolation images: 292\n",
            "total training violation images: 386\n",
            "total validation nonviolation images: 45\n",
            "total validation violation images: 97\n"
          ]
        }
      ],
      "source": [
        "train_nonviolation_names = [f for f in os.listdir(train_nonviolation_dir)]\n",
        "\n",
        "print(train_nonviolation_names[:10])\n",
        "\n",
        "train_violation_names = [f for f in os.listdir(train_violation_dir)]\n",
        "print(train_violation_names[:10])\n",
        "\n",
        "validation_nonviolation_hames = [f for f in os.listdir(valid_nonviolation_dir)]\n",
        "print(validation_nonviolation_hames[:10])\n",
        "\n",
        "validation_violation_names = [f for f in os.listdir(valid_violation_dir)]\n",
        "print(validation_violation_names[:10])\n",
        "\n",
        "print()\n",
        "\n",
        "print('total training nonviolation images:', len(os.listdir(train_nonviolation_dir)))\n",
        "print('total training violation images:', len(os.listdir(train_violation_dir)))\n",
        "print('total validation nonviolation images:', len(os.listdir(valid_nonviolation_dir)))\n",
        "print('total validation violation images:', len(os.listdir(valid_violation_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O11xhjEdt-jT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications.resnet import ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr2-JR6suDzY",
        "outputId": "8fad9ae8-7e0b-47f6-e96a-42726843cdb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "res_model = ResNet50(input_shape = (200, 200, 3), \n",
        "                                weights='imagenet',\n",
        "                                include_top = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XRE1-FSOAJY"
      },
      "outputs": [],
      "source": [
        "for layer in res_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xBBItHpOtIk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "\n",
        "x = tf.keras.layers.Flatten()(res_model.output)\n",
        "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs = res_model.input, outputs = x)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = 'adam', #SGD(learning_rate=0.001, momentum=0.9)\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODpQSCJpuNsB",
        "outputId": "e355f3ee-065f-42cf-f550-5a7096b92254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 678 images belonging to 2 classes.\n",
            "Found 142 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Directory with our training pictures\n",
        "train_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training') \n",
        "\n",
        "# Directory with our validation pictures\n",
        "valid_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation') \n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,  # source directory for training images\n",
        "        classes = ['Non_Violation', 'Violation'],\n",
        "        target_size = (200, 200),  # Images resized to 200x200\n",
        "        batch_size = 32, #128\n",
        "        # Use binary labels\n",
        "        class_mode = 'binary')\n",
        "\n",
        "# Flow validation images in batches of 16 using valid_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        valid_dir,  # source directory for training images\n",
        "        classes = ['Non_violation', 'Violation'],\n",
        "        target_size = (200, 200),  # Images resized to 200x200\n",
        "        batch_size = 16, #32\n",
        "        # Use binary labels\n",
        "        class_mode = 'binary',\n",
        "        shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUVXD_PHuWtU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLiiAyVtueHq",
        "outputId": "bbce7404-d055-4c9f-80dd-8011cd238e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 173s 8s/step - loss: 2.6433 - accuracy: 0.5442 - val_loss: 2.6424 - val_accuracy: 0.3169\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.8906 - accuracy: 0.6401 - val_loss: 1.1294 - val_accuracy: 0.6831\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.6061 - accuracy: 0.7065 - val_loss: 0.7653 - val_accuracy: 0.6831\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.4434 - accuracy: 0.7965 - val_loss: 0.6218 - val_accuracy: 0.6690\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.3929 - accuracy: 0.8378 - val_loss: 0.6046 - val_accuracy: 0.6831\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.3563 - accuracy: 0.8392 - val_loss: 0.6081 - val_accuracy: 0.7042\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.3604 - accuracy: 0.8437 - val_loss: 0.5745 - val_accuracy: 0.7394\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.3598 - accuracy: 0.8510 - val_loss: 0.5718 - val_accuracy: 0.7042\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.3124 - accuracy: 0.8702 - val_loss: 0.5827 - val_accuracy: 0.7535\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.3629 - accuracy: 0.8348 - val_loss: 0.6830 - val_accuracy: 0.6338\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "      # steps_per_epoch=9,  \n",
        "      epochs = 10,\n",
        "      verbose = 1,\n",
        "      validation_data = validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po8UIov4uu3n",
        "outputId": "3f64a5be-5e07-43d7-a8a8-c42e5010c10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 722 images belonging to 1 classes.\n",
            "Violations: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "Accuracy:  0.5969529085872576\n",
            "\n",
            "Found 567 images belonging to 1 classes.\n",
            "Non_violations: [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
            "Accuracy:  0.0582010582010582\n"
          ]
        }
      ],
      "source": [
        "test_dir = os.path.join('gdrive/MyDrive/Data/Data_collection2/other_animals')\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# Testing on all violation images\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        classes=['Violation'], \n",
        "        target_size=(200, 200),\n",
        "        batch_size=1,\n",
        "        shuffle=False)\n",
        "\n",
        "pred = model.predict(test_data_gen)\n",
        "len = pred.shape[0]\n",
        "probabilities = [1 if x > 0.5 else 0 for x in pred] # 0 means correct\n",
        "print(\"Violations:\", probabilities) # violations checked\n",
        "print('Accuracy: ', sum(probabilities)/len)\n",
        "\n",
        "y_true = [1 for i in range(len)]\n",
        "\n",
        "print()\n",
        "\n",
        "# Testing on all non-violation images\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        classes=['Non_violation'], \n",
        "        target_size=(200, 200),\n",
        "        batch_size=1,\n",
        "        # class_mode = 'binary'\n",
        "        shuffle=False)\n",
        "\n",
        "pred = model.predict(test_data_gen)\n",
        "len = pred.shape[0]\n",
        "probabilities2 = [0 if x > 0.5 else 1 for x in pred] # 1 means correct\n",
        "print(\"Non_violations:\", probabilities2) # non-violation checked\n",
        "correct = 0\n",
        "for i in range(len):\n",
        "    if probabilities2[i]==0: correct+=1\n",
        "y_true += [0 for i in range(len)]\n",
        "print('Accuracy: ', correct/len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "tne4ELACI5WS",
        "outputId": "87fab2b9-2e0c-4a3d-f75b-e57b56c6740c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 0.3599689681923972\n",
            "F1 score: 0.5109662122110255\n",
            "Recall: 0.5969529085872576\n",
            "Precision: 0.4466321243523316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "probs = probabilities + probabilities2\n",
        "\n",
        "cm = confusion_matrix(y_true, probs)\n",
        "map = sns.heatmap(cm, annot=True, fmt='d', cmap = 'Blues')\n",
        "map.set(xlabel='Predicted Label', ylabel='True Label')\n",
        "\n",
        "print ('Overall Accuracy:', accuracy_score(y_true, probs))\n",
        "print ('F1 score:', f1_score(y_true, probs))\n",
        "print ('Recall:', recall_score(y_true, probs))\n",
        "print ('Precision:', precision_score(y_true, probs))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RESNET_Keras_Violation_Classifier_Lions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}