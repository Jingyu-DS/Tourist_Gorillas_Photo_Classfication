{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGpMrGgYnwsP",
        "outputId": "c624e3b4-142d-4f8e-c9a7-85bd159d8adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6LspcE_pFxT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Directory with our training non-violation pictures\n",
        "train_nonviolation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training/Non_Violation') \n",
        "\n",
        "# Directory with our training violation pictures\n",
        "train_violation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training/Violation') \n",
        "\n",
        "# Directory with our validation non-violation pictures\n",
        "valid_nonviolation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation/Non_violation') \n",
        "\n",
        "# Directory with our validation violation pictures\n",
        "valid_violation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation/Violation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgReGUpCtzjS",
        "outputId": "9f4a3e11-51fe-4f6c-e94c-69812b47a384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IMG_0490.jpeg', 'IMG_0493.jpeg', 'IMG_0497.jpeg', 'IMG_2793.jpeg', 'IMG_0498.jpeg', 'IMG_2750.jpeg', 'IMG_0494.jpeg', 'IMG_2740.jpeg', 'IMG_2795.jpeg', 'IMG_2777.jpeg']\n",
            "['IMG_5609.JPG', 'IMG_5637.JPG', 'IMG_5623.JPG', 'IMG_5595.JPG', 'IMG_5634.JPG', 'IMG_5581.JPG', 'IMG_5542.JPG', 'IMG_5580.JPG', 'IMG_5635.JPG', 'IMG_5621.JPG']\n",
            "['IMG_8562.JPG', 'IMG_8563.JPG', 'IMG_8564.JPG', 'IMG_8561.JPG', 'IMG_8559.JPG', 'IMG_1736.JPG', 'IMG_1737.JPG', 'IMG_1738.JPG', 'IMG_1739.JPG', 'IMG_1741.JPG']\n",
            "['IMG_8589.JPG', 'IMG_8588.JPG', 'IMG_5656.JPG', 'IMG_5657.JPG', 'IMG_8570.JPG', 'IMG_8565.JPG', 'IMG_5687.JPG', 'IMG_8573.JPG', 'IMG_8567.JPG', 'IMG_8572.JPG']\n",
            "\n",
            "total training nonviolation images: 292\n",
            "total training violation images: 386\n",
            "total validation nonviolation images: 45\n",
            "total validation violation images: 97\n"
          ]
        }
      ],
      "source": [
        "train_nonviolation_names = [f for f in os.listdir(train_nonviolation_dir)]\n",
        "\n",
        "print(train_nonviolation_names[:10])\n",
        "\n",
        "train_violation_names = [f for f in os.listdir(train_violation_dir)]\n",
        "print(train_violation_names[:10])\n",
        "\n",
        "validation_nonviolation_names = [f for f in os.listdir(valid_nonviolation_dir)]\n",
        "print(validation_nonviolation_names[:10])\n",
        "\n",
        "validation_violation_names = [f for f in os.listdir(valid_violation_dir)]\n",
        "print(validation_violation_names[:10])\n",
        "\n",
        "print()\n",
        "\n",
        "print('total training nonviolation images:', len(os.listdir(train_nonviolation_dir)))\n",
        "print('total training violation images:', len(os.listdir(train_violation_dir)))\n",
        "print('total validation nonviolation images:', len(os.listdir(valid_nonviolation_dir)))\n",
        "print('total validation violation images:', len(os.listdir(valid_violation_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O11xhjEdt-jT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications.densenet import DenseNet169"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr2-JR6suDzY",
        "outputId": "5e4984e1-4e98-47b4-8152-f76cf10ef23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 0s 0us/step\n",
            "51888128/51877672 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "dense_model = DenseNet169(input_shape = (200, 200, 3), \n",
        "                                weights='imagenet',\n",
        "                                include_top = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XRE1-FSOAJY"
      },
      "outputs": [],
      "source": [
        "for layer in dense_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xBBItHpOtIk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "\n",
        "x = tf.keras.layers.Flatten()(dense_model.output)\n",
        "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs = dense_model.input, outputs = x)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = SGD(learning_rate=0.001, momentum=0.9), #SGD(learning_rate=0.001, momentum=0.9)\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODpQSCJpuNsB",
        "outputId": "2d26eab5-e008-4342-bc22-14ce31af4cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 678 images belonging to 2 classes.\n",
            "Found 142 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Directory with our training pictures\n",
        "train_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training') \n",
        "\n",
        "# Directory with our validation pictures\n",
        "valid_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation') \n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,  # source directory for training images\n",
        "        classes = ['Non_Violation', 'Violation'],\n",
        "        target_size = (200, 200),  # Images resized to 200x200\n",
        "        batch_size = 32, #128\n",
        "        # Use binary labels\n",
        "        class_mode = 'binary')\n",
        "\n",
        "# Flow validation images in batches of 16 using valid_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        valid_dir,  # source directory for training images\n",
        "        classes = ['Non_violation', 'Violation'],\n",
        "        target_size = (200, 200),  # Images resized to 200x200\n",
        "        batch_size = 16, #32\n",
        "        # Use binary labels\n",
        "        class_mode = 'binary',\n",
        "        shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUVXD_PHuWtU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLiiAyVtueHq",
        "outputId": "57a51bcd-4e7c-4b45-95eb-70687bae7222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 148s 6s/step - loss: 0.7237 - accuracy: 0.8186 - val_loss: 1.3007 - val_accuracy: 0.7887\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 121s 6s/step - loss: 0.2101 - accuracy: 0.9558 - val_loss: 1.0634 - val_accuracy: 0.8380\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 125s 6s/step - loss: 0.2697 - accuracy: 0.9469 - val_loss: 2.0303 - val_accuracy: 0.8099\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 121s 5s/step - loss: 0.1643 - accuracy: 0.9749 - val_loss: 2.2791 - val_accuracy: 0.7887\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 121s 5s/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 2.0394 - val_accuracy: 0.8099\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 121s 5s/step - loss: 0.0227 - accuracy: 0.9912 - val_loss: 2.0587 - val_accuracy: 0.7958\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 121s 6s/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 1.9554 - val_accuracy: 0.8028\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 126s 6s/step - loss: 0.0047 - accuracy: 0.9971 - val_loss: 2.4297 - val_accuracy: 0.7887\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 127s 6s/step - loss: 0.0070 - accuracy: 0.9971 - val_loss: 1.6592 - val_accuracy: 0.8239\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 125s 6s/step - loss: 1.0692e-04 - accuracy: 1.0000 - val_loss: 1.8445 - val_accuracy: 0.8239\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "      # steps_per_epoch=9,  \n",
        "      epochs = 10,\n",
        "      verbose = 1,\n",
        "      validation_data = validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po8UIov4uu3n",
        "outputId": "40993e65-c4c6-4a32-b5e7-2acc2a38aae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 722 images belonging to 1 classes.\n",
            "Violations: [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "Accuracy:  0.8864265927977839\n",
            "\n",
            "Found 567 images belonging to 1 classes.\n",
            "Non_violations: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "Accuracy:  0.2998236331569665\n"
          ]
        }
      ],
      "source": [
        "test_dir = os.path.join('gdrive/MyDrive/Data/Data_collection2/mixed_data')\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# Testing on all violation images\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        classes=['Violation'], \n",
        "        target_size=(200, 200),\n",
        "        batch_size=1,\n",
        "        shuffle=False)\n",
        "\n",
        "pred = model.predict(test_data_gen)\n",
        "len = pred.shape[0]\n",
        "probabilities = [1 if x > 0.5 else 0 for x in pred] # 0 means correct\n",
        "print(\"Violations:\", probabilities) # violations checked\n",
        "print('Accuracy: ', sum(probabilities)/len)\n",
        "\n",
        "y_true = [1 for i in range(len)]\n",
        "\n",
        "print()\n",
        "\n",
        "# Testing on all non-violation images\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        classes=['Non_violation'], \n",
        "        target_size=(200, 200),\n",
        "        batch_size=1,\n",
        "        # class_mode = 'binary'\n",
        "        shuffle=False)\n",
        "\n",
        "pred = model.predict(test_data_gen)\n",
        "len = pred.shape[0]\n",
        "probabilities2 = [0 if x > 0.5 else 1 for x in pred] # 1 means correct\n",
        "print(\"Non_violations:\", probabilities2) # non-violation checked\n",
        "correct = 0\n",
        "for i in range(len):\n",
        "    if probabilities2[i]==0: correct+=1\n",
        "y_true += [0 for i in range(len)]\n",
        "print('Accuracy: ', correct/len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "450lGVgau2Nr",
        "outputId": "7c5b633e-4456-4f8a-d05e-3b10fae1a42f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 0.6283941039565555\n",
            "F1 score: 0.7276861853325753\n",
            "Recall: 0.8864265927977839\n",
            "Precision: 0.6171648987463838\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "probs = probabilities + probabilities2\n",
        "\n",
        "cm = confusion_matrix(y_true, probs)\n",
        "map = sns.heatmap(cm, annot=True, fmt='d', cmap = 'Blues')\n",
        "map.set(xlabel='Predicted Label', ylabel='True Label')\n",
        "\n",
        "print ('Overall Accuracy:', accuracy_score(y_true, probs))\n",
        "print ('F1 score:', f1_score(y_true, probs))\n",
        "print ('Recall:', recall_score(y_true, probs))\n",
        "print ('Precision:', precision_score(y_true, probs))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DenseNet_Violation_Classifier_Lions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}