{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGpMrGgYnwsP",
        "outputId": "09c2d5be-e840-4bf6-e4f7-cf4e0f292d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6LspcE_pFxT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Directory with our training non-violation pictures\n",
        "train_nonviolation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training/Non_Violation') \n",
        "\n",
        "# Directory with our training violation pictures\n",
        "train_violation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training/Violation') \n",
        "\n",
        "# Directory with our validation non-violation pictures\n",
        "valid_nonviolation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation/Non_violation') \n",
        "\n",
        "# Directory with our validation violation pictures\n",
        "valid_violation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation/Violation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgReGUpCtzjS",
        "outputId": "d1fc190d-2c4d-45ba-887f-f0aca7c54455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['_2_2994144.jpg', 'Copy of _6_5523581.jpg', '_0_5482144.jpg', '_4_27430.jpg', '_11_1737337.jpg', '_0_3027222.jpg', '_0_5758239.jpg', '_2_3170619.jpg', '_2_2223697.jpg', 'image19.png']\n",
            "['Cpic22.jpeg', 'Cpic32.jpeg', 'c_photo13.jpg', 'Cpic37.jpeg', 'Cpic39.jpeg', 'Cpic4.jpg', 'Cpic35.jpeg', 'Cpic30.jpeg', 'c_photo14.jpg', 'Cpic6.jpeg']\n",
            "['IMG_8562.JPG', 'IMG_8563.JPG', 'IMG_8564.JPG', 'IMG_8561.JPG', 'IMG_8559.JPG', 'IMG_1736.JPG', 'IMG_1737.JPG', 'IMG_1738.JPG', 'IMG_1739.JPG', 'IMG_1741.JPG']\n",
            "['IMG_8589.JPG', 'IMG_8588.JPG', 'IMG_5656.JPG', 'IMG_5657.JPG', 'IMG_8570.JPG', 'IMG_8565.JPG', 'IMG_5687.JPG', 'IMG_8573.JPG', 'IMG_8567.JPG', 'IMG_8572.JPG']\n",
            "\n",
            "total training nonviolation images: 567\n",
            "total training violation images: 722\n",
            "total validation nonviolation images: 45\n",
            "total validation violation images: 97\n"
          ]
        }
      ],
      "source": [
        "train_nonviolation_names = [f for f in os.listdir(train_nonviolation_dir)]\n",
        "\n",
        "print(train_nonviolation_names[:10])\n",
        "\n",
        "train_violation_names = [f for f in os.listdir(train_violation_dir)]\n",
        "print(train_violation_names[:10])\n",
        "\n",
        "validation_nonviolation_names = [f for f in os.listdir(valid_nonviolation_dir)]\n",
        "print(validation_nonviolation_names[:10])\n",
        "\n",
        "validation_violation_names = [f for f in os.listdir(valid_violation_dir)]\n",
        "print(validation_violation_names[:10])\n",
        "\n",
        "print()\n",
        "\n",
        "print('total training nonviolation images:', len(os.listdir(train_nonviolation_dir)))\n",
        "print('total training violation images:', len(os.listdir(train_violation_dir)))\n",
        "print('total validation nonviolation images:', len(os.listdir(valid_nonviolation_dir)))\n",
        "print('total validation violation images:', len(os.listdir(valid_violation_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O11xhjEdt-jT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr2-JR6suDzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c3095e-1955-4b27-f8cd-cd5837073b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg_model = VGG16(input_shape = (200, 200, 3), \n",
        "                                weights='imagenet',\n",
        "                                include_top = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg_model.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "4XRE1-FSOAJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "\n",
        "x = tf.keras.layers.Flatten()(vgg_model.output)\n",
        "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs = vgg_model.input, outputs = x)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = SGD(learning_rate=0.001, momentum=0.9), #SGD(learning_rate=0.001, momentum=0.9)\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2xBBItHpOtIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODpQSCJpuNsB",
        "outputId": "c70834df-6c15-484c-9ca2-9dff0d2f76ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1289 images belonging to 2 classes.\n",
            "Found 142 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Directory with our training pictures\n",
        "train_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training') \n",
        "\n",
        "# Directory with our validation pictures\n",
        "valid_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation') \n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,  # source directory for training images\n",
        "        classes = ['Non_Violation', 'Violation'],\n",
        "        target_size = (200, 200),  # Images resized to 200x200\n",
        "        batch_size = 32, #128\n",
        "        # Use binary labels\n",
        "        class_mode = 'binary')\n",
        "\n",
        "# Flow validation images in batches of 16 using valid_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        valid_dir,  # source directory for training images\n",
        "        classes = ['Non_violation', 'Violation'],\n",
        "        target_size = (200, 200),  # Images resized to 200x200\n",
        "        batch_size = 16, #32\n",
        "        # Use binary labels\n",
        "        class_mode = 'binary',\n",
        "        shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUVXD_PHuWtU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "      # steps_per_epoch=9,  \n",
        "      epochs = 10,\n",
        "      verbose = 1,\n",
        "      validation_data = validation_generator)"
      ],
      "metadata": {
        "id": "wRDkeZpFWRw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po8UIov4uu3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22812777-e58c-4868-ed10-d8a856bab0df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 722 images belonging to 1 classes.\n",
            "Violations: [0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]\n",
            "Accuracy:  0.775623268698061\n",
            "\n",
            "Found 567 images belonging to 1 classes.\n",
            "Non_violations: [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n",
            "Accuracy:  0.13580246913580246\n"
          ]
        }
      ],
      "source": [
        "test_dir = os.path.join('gdrive/MyDrive/Data/Data_collection2/other_animals')\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# Testing on all violation images\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        classes=['Violation'], \n",
        "        target_size=(200, 200),\n",
        "        batch_size=1,\n",
        "        shuffle=False)\n",
        "\n",
        "pred = model.predict(test_data_gen)\n",
        "len = pred.shape[0]\n",
        "probabilities = [1 if x > 0.5 else 0 for x in pred] # 0 means correct\n",
        "print(\"Violations:\", probabilities) # violations checked\n",
        "print('Accuracy: ', sum(probabilities)/len)\n",
        "\n",
        "y_true = [1 for i in range(len)]\n",
        "\n",
        "print()\n",
        "\n",
        "# Testing on all non-violation images\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        classes=['Non_violation'], \n",
        "        target_size=(200, 200),\n",
        "        batch_size=1,\n",
        "        # class_mode = 'binary'\n",
        "        shuffle=False)\n",
        "\n",
        "pred = model.predict(test_data_gen)\n",
        "len = pred.shape[0]\n",
        "probabilities2 = [0 if x > 0.5 else 1 for x in pred] # 1 means correct\n",
        "print(\"Non_violations:\", probabilities2) # non-violation checked\n",
        "correct = 0\n",
        "for i in range(len):\n",
        "    if probabilities2[i]==0: correct+=1\n",
        "y_true += [0 for i in range(len)]\n",
        "print('Accuracy: ', correct/len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tne4ELACI5WS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "0cdb875a-849b-487c-a813-1dd6046f1640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 0.49418153607447635\n",
            "F1 score: 0.6320541760722347\n",
            "Recall: 0.775623268698061\n",
            "Precision: 0.5333333333333333\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "probs = probabilities + probabilities2\n",
        "\n",
        "cm = confusion_matrix(y_true, probs)\n",
        "map = sns.heatmap(cm, annot=True, fmt='d', cmap = 'Blues')\n",
        "map.set(xlabel='Predicted Label', ylabel='True Label')\n",
        "\n",
        "print ('Overall Accuracy:', accuracy_score(y_true, probs))\n",
        "print ('F1 score:', f1_score(y_true, probs))\n",
        "print ('Recall:', recall_score(y_true, probs))\n",
        "print ('Precision:', precision_score(y_true, probs))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "VGG_Keras_Violation_Classifier_Lions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}