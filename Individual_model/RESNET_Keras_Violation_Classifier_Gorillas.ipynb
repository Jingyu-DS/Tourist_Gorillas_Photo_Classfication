{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGpMrGgYnwsP",
        "outputId": "5f19ce51-5eae-483a-9470-1f7f3a2cab92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p6LspcE_pFxT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Directory with our training non-violation pictures\n",
        "train_nonviolation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Gorillas_Testing_data_2/Non_violation') \n",
        "\n",
        "# Directory with our training violation pictures\n",
        "train_violation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Gorillas_Testing_data_2/Violation') \n",
        "\n",
        "# Directory with our validation non-violation pictures\n",
        "valid_nonviolation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Gorillas_Validation/Non_violation') \n",
        "\n",
        "# Directory with our validation violation pictures\n",
        "valid_violation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Gorillas_Validation/Violation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgReGUpCtzjS",
        "outputId": "3a1b6af0-c12a-410a-c80b-01f08b411e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Copy of _0_1297902 (1).jpg', 'Copy of _0_1297902.jpg', 'Copy of _0_993035.jpg', 'Copy of _0_2264699.jpg', 'Copy of _9_1167519.jpg', 'Copy of _2_4334496.jpg', 'Copy of _2_2431837.jpg', 'Copy of _2_2462297.jpg', 'Copy of _2_3204331.jpg', 'Copy of _2_4004520.jpg']\n",
            "['mg28.jpg', 'photo16.jpg', 'image34.jpg', 'mg7.jpg', 'mg17 4.16.14 PM.jpg', 'photo12.jpg', 'mg30.jpg', 'image9.jpeg', 'mg11.jpg', 'photo13.jpeg']\n",
            "['Copy of _0_6460006.jpg', 'Copy of _0_9377298.jpg', 'Copy of _0_7089029.jpg', 'Copy of _0_6874368.jpg', 'Copy of _1_8272983.jpg', 'Copy of _1_6872858.jpg', 'Copy of _1_6386370.jpg', 'Copy of _1_3090079.jpg', 'Copy of _3_3168220.jpg', 'Copy of _3_2980678.jpg']\n",
            "['image48.jpg', 'image47.jpg', 'mg3.jpg', 'image51.jpg', 'image40.jpg', 'image43.jpg', 'image41.jpg', 'image44.jpg', 'git17.jpeg', 'git23.jpeg']\n",
            "\n",
            "total training violation images: 92\n",
            "total training violation images: 95\n",
            "total validation nonviolation images: 36\n",
            "total validation violation images: 40\n"
          ]
        }
      ],
      "source": [
        "train_nonviolation_names = [f for f in os.listdir(train_nonviolation_dir)]\n",
        "\n",
        "print(train_nonviolation_names[:10])\n",
        "\n",
        "train_violation_names = [f for f in os.listdir(train_violation_dir)]\n",
        "print(train_violation_names[:10])\n",
        "\n",
        "validation_nonviolation_hames = [f for f in os.listdir(valid_nonviolation_dir)]\n",
        "print(validation_nonviolation_hames[:10])\n",
        "\n",
        "validation_violation_names = [f for f in os.listdir(valid_violation_dir)]\n",
        "print(validation_violation_names[:10])\n",
        "\n",
        "print()\n",
        "\n",
        "print('total training violation images:', len(os.listdir(train_nonviolation_dir)))\n",
        "print('total training violation images:', len(os.listdir(train_violation_dir)))\n",
        "print('total validation nonviolation images:', len(os.listdir(valid_nonviolation_dir)))\n",
        "print('total validation violation images:', len(os.listdir(valid_violation_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O11xhjEdt-jT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications.resnet import ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr2-JR6suDzY",
        "outputId": "9bd3b397-f512-4684-f1aa-5198f22cf51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 2s 0us/step\n",
            "94781440/94765736 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "res_model = ResNet50(input_shape = (200, 200, 3), \n",
        "                                weights='imagenet',\n",
        "                                include_top = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XRE1-FSOAJY"
      },
      "outputs": [],
      "source": [
        "for layer in res_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xBBItHpOtIk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "\n",
        "x = tf.keras.layers.Flatten()(res_model.output)\n",
        "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs = res_model.input, outputs = x)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = SGD(learning_rate=0.001, momentum=0.9), #SGD(learning_rate=0.001, momentum=0.9)\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODpQSCJpuNsB",
        "outputId": "b562b38f-c0fa-4963-e2cb-8a67fbc06f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 187 images belonging to 2 classes.\n",
            "Found 76 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Directory with our training pictures\n",
        "train_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Gorillas_Testing_data_2') \n",
        "\n",
        "# Directory with our validation pictures\n",
        "valid_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Gorillas_Validation') \n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,  # source directory for training images\n",
        "        classes = ['Non_violation', 'Violation'],\n",
        "        target_size = (200, 200),  # Images resized to 200x200\n",
        "        batch_size = 32, #128\n",
        "        # Use binary labels\n",
        "        class_mode = 'binary')\n",
        "\n",
        "# Flow validation images in batches of 16 using valid_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        valid_dir,  # source directory for training images\n",
        "        classes = ['Non_violation', 'Violation'],\n",
        "        target_size = (200, 200),  # Images resized to 200x200\n",
        "        batch_size = 16, #32\n",
        "        # Use binary labels\n",
        "        class_mode = 'binary',\n",
        "        shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUVXD_PHuWtU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLiiAyVtueHq",
        "outputId": "66b2dead-f7df-4277-803e-6e10b55ee411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 181s 30s/step - loss: 3.3901 - accuracy: 0.5294 - val_loss: 22.8254 - val_accuracy: 0.4737\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 40s 7s/step - loss: 19.0288 - accuracy: 0.5187 - val_loss: 5.5598 - val_accuracy: 0.4737\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 40s 7s/step - loss: 3.0776 - accuracy: 0.6150 - val_loss: 7.6884 - val_accuracy: 0.5263\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 40s 7s/step - loss: 7.3185 - accuracy: 0.4866 - val_loss: 14.0180 - val_accuracy: 0.4737\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 39s 7s/step - loss: 9.3921 - accuracy: 0.5775 - val_loss: 11.6625 - val_accuracy: 0.4737\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 39s 7s/step - loss: 7.7199 - accuracy: 0.5668 - val_loss: 3.9639 - val_accuracy: 0.6316\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 39s 7s/step - loss: 1.6649 - accuracy: 0.7647 - val_loss: 1.7990 - val_accuracy: 0.7105\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 40s 7s/step - loss: 1.5759 - accuracy: 0.7701 - val_loss: 1.7282 - val_accuracy: 0.7500\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 40s 7s/step - loss: 1.7171 - accuracy: 0.7701 - val_loss: 1.4779 - val_accuracy: 0.7105\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 40s 7s/step - loss: 1.3578 - accuracy: 0.8182 - val_loss: 1.9108 - val_accuracy: 0.7368\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "      # steps_per_epoch=9,  \n",
        "      epochs = 10,\n",
        "      verbose = 1,\n",
        "      validation_data = validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po8UIov4uu3n",
        "outputId": "5c4b95ea-f19c-43c2-96ba-79662a29e16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 23 images belonging to 1 classes.\n",
            "Violations: [0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "Accuracy:  0.34782608695652173\n",
            "\n",
            "Found 53 images belonging to 1 classes.\n",
            "Non_violations: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]\n",
            "Accuracy:  0.16981132075471697\n"
          ]
        }
      ],
      "source": [
        "test_dir = os.path.join('gdrive/MyDrive/Data/Data_collection2/other_animals')\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# Testing on all violation images\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        classes=['Violation'], \n",
        "        target_size=(200, 200),\n",
        "        batch_size=1,\n",
        "        shuffle=False)\n",
        "\n",
        "pred = model.predict(test_data_gen)\n",
        "len = pred.shape[0]\n",
        "probabilities = [1 if x > 0.5 else 0 for x in pred] # 0 means correct\n",
        "print(\"Violations:\", probabilities) # violations checked\n",
        "print('Accuracy: ', sum(probabilities)/len)\n",
        "\n",
        "y_true = [1 for i in range(len)]\n",
        "\n",
        "print()\n",
        "\n",
        "# Testing on all non-violation images\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        classes=['Non_violation'], \n",
        "        target_size=(200, 200),\n",
        "        batch_size=1,\n",
        "        # class_mode = 'binary'\n",
        "        shuffle=False)\n",
        "\n",
        "pred = model.predict(test_data_gen)\n",
        "len = pred.shape[0]\n",
        "probabilities2 = [0 if x > 0.5 else 1 for x in pred] # 1 means correct\n",
        "print(\"Non_violations:\", probabilities2) # non-violation checked\n",
        "correct = 0\n",
        "for i in range(len):\n",
        "    if probabilities2[i]==0: correct+=1\n",
        "y_true += [0 for i in range(len)]\n",
        "print('Accuracy: ', correct/len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "tne4ELACI5WS",
        "outputId": "4b0e83b1-95f7-4552-d10b-194d3aefcec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 0.2236842105263158\n",
            "F1 score: 0.21333333333333332\n",
            "Recall: 0.34782608695652173\n",
            "Precision: 0.15384615384615385\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "probs = probabilities + probabilities2\n",
        "\n",
        "cm = confusion_matrix(y_true, probs)\n",
        "map = sns.heatmap(cm, annot=True, fmt='d', cmap = 'Blues')\n",
        "map.set(xlabel='Predicted Label', ylabel='True Label')\n",
        "\n",
        "print ('Overall Accuracy:', accuracy_score(y_true, probs))\n",
        "print ('F1 score:', f1_score(y_true, probs))\n",
        "print ('Recall:', recall_score(y_true, probs))\n",
        "print ('Precision:', precision_score(y_true, probs))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RESNET_Keras_Violation_Classifier_Gorillas.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}