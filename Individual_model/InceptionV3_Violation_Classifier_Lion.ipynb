{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGpMrGgYnwsP",
        "outputId": "dac52cac-c124-43d9-d7ab-b8bdd5d366ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6LspcE_pFxT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Directory with our training non-violation pictures\n",
        "train_nonviolation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training/Non_Violation') \n",
        "\n",
        "# Directory with our training violation pictures\n",
        "train_violation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training/Violation') \n",
        "\n",
        "# Directory with our validation non-violation pictures\n",
        "valid_nonviolation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation/Non_violation') \n",
        "\n",
        "# Directory with our validation violation pictures\n",
        "valid_violation_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation/Violation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgReGUpCtzjS",
        "outputId": "2b01be40-d2f3-48df-9363-0c26f46d9b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IMG_0490.jpeg', 'IMG_0493.jpeg', 'IMG_0497.jpeg', 'IMG_2793.jpeg', 'IMG_0498.jpeg', 'IMG_2750.jpeg', 'IMG_0494.jpeg', 'IMG_2740.jpeg', 'IMG_2795.jpeg', 'IMG_2777.jpeg']\n",
            "['IMG_5609.JPG', 'IMG_5637.JPG', 'IMG_5623.JPG', 'IMG_5595.JPG', 'IMG_5634.JPG', 'IMG_5581.JPG', 'IMG_5542.JPG', 'IMG_5580.JPG', 'IMG_5635.JPG', 'IMG_5621.JPG']\n",
            "['IMG_8562.JPG', 'IMG_8563.JPG', 'IMG_8564.JPG', 'IMG_8561.JPG', 'IMG_8559.JPG', 'IMG_1736.JPG', 'IMG_1737.JPG', 'IMG_1738.JPG', 'IMG_1739.JPG', 'IMG_1741.JPG']\n",
            "['IMG_8589.JPG', 'IMG_8588.JPG', 'IMG_5656.JPG', 'IMG_5657.JPG', 'IMG_8570.JPG', 'IMG_8565.JPG', 'IMG_5687.JPG', 'IMG_8573.JPG', 'IMG_8567.JPG', 'IMG_8572.JPG']\n",
            "\n",
            "total training nonviolation images: 292\n",
            "total training violation images: 386\n",
            "total validation nonviolation images: 45\n",
            "total validation violation images: 97\n"
          ]
        }
      ],
      "source": [
        "train_nonviolation_names = [f for f in os.listdir(train_nonviolation_dir)]\n",
        "\n",
        "print(train_nonviolation_names[:10])\n",
        "\n",
        "train_violation_names = [f for f in os.listdir(train_violation_dir)]\n",
        "print(train_violation_names[:10])\n",
        "\n",
        "validation_nonviolation_names = [f for f in os.listdir(valid_nonviolation_dir)]\n",
        "print(validation_nonviolation_names[:10])\n",
        "\n",
        "validation_violation_names = [f for f in os.listdir(valid_violation_dir)]\n",
        "print(validation_violation_names[:10])\n",
        "\n",
        "print()\n",
        "\n",
        "print('total training nonviolation images:', len(os.listdir(train_nonviolation_dir)))\n",
        "print('total training violation images:', len(os.listdir(train_violation_dir)))\n",
        "print('total validation nonviolation images:', len(os.listdir(valid_nonviolation_dir)))\n",
        "print('total validation violation images:', len(os.listdir(valid_violation_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O11xhjEdt-jT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications.inception_v3 import InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr2-JR6suDzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9b9ce2-8c1b-49fd-aa50-11ebdbf66872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "inc_model = InceptionV3(input_shape = (200, 200, 3), \n",
        "                                weights='imagenet',\n",
        "                                include_top = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in inc_model.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "4XRE1-FSOAJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "\n",
        "x = tf.keras.layers.Flatten()(inc_model.output)\n",
        "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs = inc_model.input, outputs = x)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = SGD(learning_rate=0.001, momentum=0.9),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2xBBItHpOtIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODpQSCJpuNsB",
        "outputId": "8ed942a3-d7b4-4dd5-a16d-bb002c8b2b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 678 images belonging to 2 classes.\n",
            "Found 142 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Directory with our training pictures\n",
        "train_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_training') \n",
        "\n",
        "# Directory with our validation pictures\n",
        "valid_dir = os.path.join('gdrive/MyDrive/Data/Data_collection1/Benchmark_validation') \n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,  # source directory for training images\n",
        "        classes = ['Non_Violation', 'Violation'],\n",
        "        target_size = (200, 200),  # Images resized to 200x200\n",
        "        batch_size = 32, #128\n",
        "        # Use binary labels\n",
        "        class_mode = 'binary')\n",
        "\n",
        "# Flow validation images in batches of 16 using valid_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        valid_dir,  # source directory for training images\n",
        "        classes = ['Non_violation', 'Violation'],\n",
        "        target_size = (200, 200),  # Images resized to 200x200\n",
        "        batch_size = 16, #32\n",
        "        # Use binary labels\n",
        "        class_mode = 'binary',\n",
        "        shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUVXD_PHuWtU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLiiAyVtueHq",
        "outputId": "b6dcf650-9e7d-4059-8a19-42e5aac93ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 138s 6s/step - loss: 0.5084 - accuracy: 0.8068 - val_loss: 0.7518 - val_accuracy: 0.8099\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 80s 4s/step - loss: 0.1843 - accuracy: 0.9351 - val_loss: 0.9223 - val_accuracy: 0.8380\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 79s 4s/step - loss: 0.0936 - accuracy: 0.9617 - val_loss: 0.9463 - val_accuracy: 0.8310\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 79s 4s/step - loss: 0.0685 - accuracy: 0.9690 - val_loss: 1.0631 - val_accuracy: 0.8169\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 79s 4s/step - loss: 0.0479 - accuracy: 0.9823 - val_loss: 1.1843 - val_accuracy: 0.8169\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 83s 4s/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.9662 - val_accuracy: 0.8521\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 80s 4s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9252 - val_accuracy: 0.8662\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 80s 4s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.8732\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 80s 4s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.8732\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 80s 4s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.8732\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "      # steps_per_epoch=9,  \n",
        "      epochs = 10,\n",
        "      verbose = 1,\n",
        "      validation_data = validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_YIbw4tIXRU",
        "outputId": "37118e2e-6555-4b23-8975-a64308910b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 722 images belonging to 1 classes.\n",
            "Violations: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "Accuracy:  0.9376731301939059\n",
            "\n",
            "Found 567 images belonging to 1 classes.\n",
            "Non_violations: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0]\n",
            "Accuracy:  0.25044091710758376\n"
          ]
        }
      ],
      "source": [
        "test_dir = os.path.join('gdrive/MyDrive/Data/Data_collection2/mixed_data')\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# Testing on all violation images\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        classes=['Violation'], \n",
        "        target_size=(200, 200),\n",
        "        batch_size=1,\n",
        "        shuffle=False)\n",
        "\n",
        "pred = model.predict(test_data_gen)\n",
        "len = pred.shape[0]\n",
        "probabilities = [1 if x > 0.5 else 0 for x in pred] # 0 means correct\n",
        "print(\"Violations:\", probabilities) # violations checked\n",
        "print('Accuracy: ', sum(probabilities)/len)\n",
        "\n",
        "y_true = [1 for i in range(len)]\n",
        "\n",
        "print()\n",
        "\n",
        "# Testing on all non-violation images\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "        directory=test_dir,\n",
        "        classes=['Non_violation'], \n",
        "        target_size=(200, 200),\n",
        "        batch_size=1,\n",
        "        # class_mode = 'binary'\n",
        "        shuffle=False)\n",
        "\n",
        "pred = model.predict(test_data_gen)\n",
        "len = pred.shape[0]\n",
        "probabilities2 = [0 if x > 0.5 else 1 for x in pred] # 1 means correct\n",
        "print(\"Non_violations:\", probabilities2) # non-violation checked\n",
        "correct = 0\n",
        "for i in range(len):\n",
        "    if probabilities2[i]==0: correct+=1\n",
        "y_true += [0 for i in range(len)]\n",
        "print('Accuracy: ', correct/len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "probs = probabilities + probabilities2\n",
        "\n",
        "cm = confusion_matrix(y_true, probs)\n",
        "map = sns.heatmap(cm, annot=True, fmt='d', cmap = 'Blues')\n",
        "map.set(xlabel='Predicted Label', ylabel='True Label')\n",
        "\n",
        "print ('Overall Accuracy:', accuracy_score(y_true, probs))\n",
        "print ('F1 score:', f1_score(y_true, probs))\n",
        "print ('Recall:', recall_score(y_true, probs))\n",
        "print ('Precision:', precision_score(y_true, probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "jGlwr5j-jax-",
        "outputId": "ae6de7f7-f9e5-4cc8-fb49-645b0f3e5198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 0.6353762606671839\n",
            "F1 score: 0.7423245614035088\n",
            "Recall: 0.9376731301939059\n",
            "Precision: 0.6143375680580763\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "InceptionV3_Violation_Classifier_Lion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}